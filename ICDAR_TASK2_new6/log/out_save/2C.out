nohup: ignoring input
/home/sjhbxs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
###########################################################
SparseTensor(indices=Tensor("BLSTM/Placeholder_2:0", shape=(?, ?), dtype=int64), values=Tensor("BLSTM/Placeholder_1:0", shape=(?,), dtype=int32), dense_shape=Tensor("BLSTM/Placeholder:0", shape=(?,), dtype=int64))
Tensor("transpose:0", shape=(?, ?, 102), dtype=float32)
Tensor("BLSTM/Placeholder_3:0", shape=(?,), dtype=int32)
loading train data, please wait--------------------- end= 
len is 0 or too long 1101121
len is 0 or too long 1067138
len is 0 or too long 1085492
len is 0 or too long 1080026
len is 0 or too long 1148610
len is 0 or too long 1161134
len is 0 or too long 1091637
len is 0 or too long 1234345
len is 0 or too long 1157057
len is 0 or too long 1078701
len is 0 or too long 1199831
len is 0 or too long 1124130
***************get image:  42606
loading validation data, please wait--------------------- end= 
len is 0 or too long 1091637
***************get image:  301
2018-05-10 00:30:48.016066: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 00:30:48.016123: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 00:30:48.016131: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 00:30:48.016137: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 00:30:48.016144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-05-10 00:30:48.627758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-10 00:30:48.628123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.09GiB
2018-05-10 00:30:48.628165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-05-10 00:30:48.628190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-05-10 00:30:48.628204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
restore is true
restore from the checkpoint/home/sjhbxs/checkout/ICDAR_task2/ICDAR_TASK2_new6/checkpoint/ocr-model-14800
=============================begin training=============================
2018-05-10 00:31:06.596827: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4575 get requests, put_count=3084 evicted_count=1000 eviction_rate=0.324254 and unsatisfied allocation rate=0.566339
2018-05-10 00:31:06.596891: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2018-05-10 00:31:17.193554: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 378 get requests, put_count=1391 evicted_count=1000 eviction_rate=0.718907 and unsatisfied allocation rate=0.0026455
2018-05-10 00:31:17.193618: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 160 to 176
2018-05-10 00:31:23.221413: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 649 get requests, put_count=1673 evicted_count=1000 eviction_rate=0.597729 and unsatisfied allocation rate=0.00154083
2018-05-10 00:31:30.620318: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 5275 get requests, put_count=5127 evicted_count=2000 eviction_rate=0.390092 and unsatisfied allocation rate=0.414218
2018-05-10 00:31:30.620378: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 409 to 449
2018-05-10 00:31:38.139626: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 5361 get requests, put_count=5491 evicted_count=2000 eviction_rate=0.364232 and unsatisfied allocation rate=0.359821
2018-05-10 00:31:38.139689: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 655 to 720
2018-05-10 00:31:47.194656: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4901 get requests, put_count=4569 evicted_count=1000 eviction_rate=0.218866 and unsatisfied allocation rate=0.293205
2018-05-10 00:31:47.194719: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 1158 to 1273
cur_epoch==== 0 cur_batch---- 99 g_step**** 14899 cost 11.468841
seq   0: origin: [21, 18, 25, 18] decoded:[18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[36, 52, 52, 42, 47, 38]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[35, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[49, 34, 47, 42, 48, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 69, 69, 83]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 54, 75, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 48, 42, 52, 42, 42, 38]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 80, 82, 51, 37]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[36, 48, 47, 49, 34, 47, 58]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 75]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 51, 53, 34, 45, 51, 34, 47, 47]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 17, 15, 83, 71, 17, 17]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[69, 82, 48, 47, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 68]
5/10 0:36:25  step===15000, Epoch 2/1000, accuracy = 0.083,avg_train_cost = 11.051, lastbatch_err = 0.609, time = 59.755,lr=0.00860058

cur_epoch==== 1 cur_batch---- 99 g_step**** 15065 cost 11.875914
save checkpoint 15200
cur_epoch==== 2 cur_batch---- 99 g_step**** 15231 cost 11.455363
cur_epoch==== 3 cur_batch---- 99 g_step**** 15397 cost 10.363131
cur_epoch==== 4 cur_batch---- 99 g_step**** 15563 cost 10.406269
save checkpoint 15600
cur_epoch==== 5 cur_batch---- 99 g_step**** 15729 cost 10.977964
cur_epoch==== 6 cur_batch---- 99 g_step**** 15895 cost 9.68173
save checkpoint 16000
seq   0: origin: [21, 18, 25, 18] decoded:[18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[36, 83, 69, 84, 38, 69]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[35, 34, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 48, 47, 42, 37, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[68, 84, 69, 79, 79, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 48, 42, 52, 42, 45, 38]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[84, 80, 69, 77, 79]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 73, 78, 75]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[38, 51, 38, 53, 34, 45, 51, 34, 47, 42, 51]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[36, 17, 52, 40, 17]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 65, 82, 79, 67]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 79]
5/10 1:2:15  step===16000, Epoch 8/1000, accuracy = 0.106,avg_train_cost = 10.370, lastbatch_err = 0.603, time = 61.096,lr=0.00851458

cur_epoch==== 7 cur_batch---- 99 g_step**** 16061 cost 9.523168
cur_epoch==== 8 cur_batch---- 99 g_step**** 16227 cost 10.359483
cur_epoch==== 9 cur_batch---- 99 g_step**** 16393 cost 9.810616
save checkpoint 16400
cur_epoch==== 10 cur_batch---- 99 g_step**** 16559 cost 9.559896
cur_epoch==== 11 cur_batch---- 99 g_step**** 16725 cost 9.586582
save checkpoint 16800
cur_epoch==== 12 cur_batch---- 99 g_step**** 16891 cost 9.802404
seq   0: origin: [21, 18, 25, 18] decoded:[18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 52, 38, 53, 47, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 45, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[48, 34, 47, 42, 52, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 42, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 79, 73, 83, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[24, 80, 69, 19, 17]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 73, 78, 75]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[38, 51, 38, 53, 34, 45, 51, 34, 47, 42, 52]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[36, 48, 52, 15, 40, 17]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 34, 51, 48, 45, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 79]
5/10 1:28:16  step===17000, Epoch 14/1000, accuracy = 0.130,avg_train_cost = 9.858, lastbatch_err = 0.559, time = 66.863,lr=0.00842943

cur_epoch==== 13 cur_batch---- 99 g_step**** 17057 cost 10.104965
save checkpoint 17200
cur_epoch==== 14 cur_batch---- 99 g_step**** 17223 cost 10.717857
cur_epoch==== 15 cur_batch---- 99 g_step**** 17389 cost 9.570498
cur_epoch==== 16 cur_batch---- 99 g_step**** 17555 cost 11.243238
save checkpoint 17600
cur_epoch==== 17 cur_batch---- 99 g_step**** 17721 cost 8.7222395
cur_epoch==== 18 cur_batch---- 99 g_step**** 17887 cost 9.538477
save checkpoint 18000
seq   0: origin: [21, 18, 25, 18] decoded:[19, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 52, 36, 53, 42, 38]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[36, 48, 47, 42, 35, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 69, 67, 65, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 65, 73, 83, 73, 73, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 80, 69, 65, 79]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 47, 38, 53, 34, 45, 51, 34, 47, 53, 47]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 40, 17]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 51, 48, 51, 36, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 68]
5/10 1:56:21  step===18000, Epoch 20/1000, accuracy = 0.153,avg_train_cost = 9.502, lastbatch_err = 0.531, time = 125.669,lr=0.00834514

cur_epoch==== 19 cur_batch---- 99 g_step**** 18053 cost 10.521785
cur_epoch==== 20 cur_batch---- 99 g_step**** 18219 cost 9.345761
cur_epoch==== 21 cur_batch---- 99 g_step**** 18385 cost 8.920477
save checkpoint 18400
cur_epoch==== 22 cur_batch---- 99 g_step**** 18551 cost 9.21346
cur_epoch==== 23 cur_batch---- 99 g_step**** 18717 cost 7.953572
save checkpoint 18800
cur_epoch==== 24 cur_batch---- 99 g_step**** 18883 cost 8.331491
seq   0: origin: [21, 18, 25, 18] decoded:[21, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 54, 40, 53, 34, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[49, 48, 48, 34, 47, 42, 52, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 73, 67, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 42, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 65, 73, 73, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 84]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 53, 34, 37]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[34, 51, 38, 53, 34, 45, 51, 34, 47, 42, 47]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 71, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[53, 48, 51, 48, 38, 44]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 79]
5/10 2:27:25  step===19000, Epoch 26/1000, accuracy = 0.189,avg_train_cost = 8.992, lastbatch_err = 0.490, time = 79.311,lr=0.00826169

cur_epoch==== 25 cur_batch---- 99 g_step**** 19049 cost 9.195546
save checkpoint 19200
cur_epoch==== 26 cur_batch---- 99 g_step**** 19215 cost 9.744331
cur_epoch==== 27 cur_batch---- 99 g_step**** 19381 cost 9.380657
cur_epoch==== 28 cur_batch---- 99 g_step**** 19547 cost 9.315059
save checkpoint 19600
cur_epoch==== 29 cur_batch---- 99 g_step**** 19713 cost 9.330051
cur_epoch==== 30 cur_batch---- 99 g_step**** 19879 cost 10.836154
save checkpoint 20000
seq   0: origin: [21, 18, 25, 18] decoded:[24, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 51, 36, 53, 47, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[36, 48, 47, 42, 37, 53]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 42, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 65, 73, 83, 76, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[84, 80, 84, 65, 79]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[34, 51, 38, 53, 34, 45, 51, 34, 47, 53]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 67, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 34, 51, 79, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 79]
5/10 3:10:19  step===20000, Epoch 32/1000, accuracy = 0.179,avg_train_cost = 8.617, lastbatch_err = 0.496, time = 147.957,lr=0.00817907

cur_epoch==== 31 cur_batch---- 99 g_step**** 20045 cost 10.154095
cur_epoch==== 32 cur_batch---- 99 g_step**** 20211 cost 9.108381
cur_epoch==== 33 cur_batch---- 99 g_step**** 20377 cost 7.9003572
save checkpoint 20400
cur_epoch==== 34 cur_batch---- 99 g_step**** 20543 cost 7.4166546
cur_epoch==== 35 cur_batch---- 99 g_step**** 20709 cost 8.481794
save checkpoint 20800
cur_epoch==== 36 cur_batch---- 99 g_step**** 20875 cost 9.735828
seq   0: origin: [21, 18, 25, 18] decoded:[19, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 52, 36, 42, 47, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 48, 37, 47, 42, 48, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 73, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 54, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 69, 82, 83, 76, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 38, 34, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 38, 53, 34, 45, 51, 34, 47, 53, 51]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[36, 48, 52, 40, 48]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[45, 79, 82, 79, 86, 38, 69]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 79]
5/10 3:55:0  step===21000, Epoch 38/1000, accuracy = 0.189,avg_train_cost = 8.313, lastbatch_err = 0.459, time = 158.542,lr=0.00809728

cur_epoch==== 37 cur_batch---- 99 g_step**** 21041 cost 8.007298
save checkpoint 21200
cur_epoch==== 38 cur_batch---- 99 g_step**** 21207 cost 7.885485
cur_epoch==== 39 cur_batch---- 99 g_step**** 21373 cost 8.267797
cur_epoch==== 40 cur_batch---- 99 g_step**** 21539 cost 7.8247905
save checkpoint 21600
cur_epoch==== 41 cur_batch---- 99 g_step**** 21705 cost 8.391989
cur_epoch==== 42 cur_batch---- 99 g_step**** 21871 cost 8.737856
save checkpoint 22000
seq   0: origin: [21, 18, 25, 18] decoded:[34, 24, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 52, 38, 53, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 34, 42, 47, 42, 52, 53]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 73, 67, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 54, 44, 42, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 65, 73, 83, 76, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 42, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 49, 42, 53, 38, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[35, 51, 38, 53, 34, 45, 51, 34, 47, 42, 51]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 67, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 51, 48, 51, 38, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 77, 69, 82, 73, 78, 79]
5/10 4:39:41  step===22000, Epoch 44/1000, accuracy = 0.203,avg_train_cost = 8.088, lastbatch_err = 0.459, time = 168.236,lr=0.00801631

cur_epoch==== 43 cur_batch---- 99 g_step**** 22037 cost 8.74146
cur_epoch==== 44 cur_batch---- 99 g_step**** 22203 cost 8.465771
cur_epoch==== 45 cur_batch---- 99 g_step**** 22369 cost 8.372347
save checkpoint 22400
cur_epoch==== 46 cur_batch---- 99 g_step**** 22535 cost 7.6470757
cur_epoch==== 47 cur_batch---- 99 g_step**** 22701 cost 9.04335
save checkpoint 22800
cur_epoch==== 48 cur_batch---- 99 g_step**** 22867 cost 7.99684
seq   0: origin: [21, 18, 25, 18] decoded:[34, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 52, 36, 42, 51, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[49, 47, 37, 37, 42, 48, 53]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[49, 82, 69, 68, 65, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 65, 73, 69, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 42, 53, 34, 37]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[38, 51, 38, 53, 34, 45, 51, 34, 47, 42, 47]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 71, 17]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 51, 48, 55, 38, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[46, 69, 82, 73, 78, 79]
5/10 5:24:22  step===23000, Epoch 50/1000, accuracy = 0.213,avg_train_cost = 7.882, lastbatch_err = 0.431, time = 179.766,lr=0.00793614

cur_epoch==== 49 cur_batch---- 99 g_step**** 23033 cost 7.9097657
cur_epoch==== 50 cur_batch---- 99 g_step**** 23199 cost 7.2221794
save checkpoint 23200
cur_epoch==== 51 cur_batch---- 99 g_step**** 23365 cost 7.9268947
cur_epoch==== 52 cur_batch---- 99 g_step**** 23531 cost 7.489291
save checkpoint 23600
cur_epoch==== 53 cur_batch---- 99 g_step**** 23697 cost 7.7715077
cur_epoch==== 54 cur_batch---- 99 g_step**** 23863 cost 7.9217486
save checkpoint 24000
seq   0: origin: [21, 18, 25, 18] decoded:[21, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 52, 36, 53, 42, 34, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 37, 42, 37, 34, 42, 48, 53]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 84, 82, 84, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 54, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 65, 73, 83, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 42, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 49, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 38, 53, 34, 45, 51, 34, 47, 53, 47]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[36, 48, 52, 40, 48]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[41, 48, 51, 48, 51, 39, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 48, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 68]
5/10 6:9:4  step===24000, Epoch 56/1000, accuracy = 0.223,avg_train_cost = 7.441, lastbatch_err = 0.423, time = 190.135,lr=0.00785678

cur_epoch==== 55 cur_batch---- 99 g_step**** 24029 cost 7.3490677
cur_epoch==== 56 cur_batch---- 99 g_step**** 24195 cost 7.7159047
cur_epoch==== 57 cur_batch---- 99 g_step**** 24361 cost 8.118452
save checkpoint 24400
cur_epoch==== 58 cur_batch---- 99 g_step**** 24527 cost 7.409889
cur_epoch==== 59 cur_batch---- 99 g_step**** 24693 cost 7.403248
save checkpoint 24800
cur_epoch==== 60 cur_batch---- 99 g_step**** 24859 cost 6.832406
seq   0: origin: [21, 18, 25, 18] decoded:[21, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 52, 36, 53, 34, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 45, 47, 42, 35, 53]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 73, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 42, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 85, 73, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 73, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[84, 80, 65, 68]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 38, 53, 34, 45, 51, 34, 47, 53, 53]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 71, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 48, 39, 38, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 70, 73, 78, 79]
5/10 6:53:45  step===25000, Epoch 62/1000, accuracy = 0.239,avg_train_cost = 7.325, lastbatch_err = 0.412, time = 200.214,lr=0.00777822

cur_epoch==== 61 cur_batch---- 99 g_step**** 25025 cost 7.1076937
cur_epoch==== 62 cur_batch---- 99 g_step**** 25191 cost 6.99687
save checkpoint 25200
cur_epoch==== 63 cur_batch---- 99 g_step**** 25357 cost 5.797536
cur_epoch==== 64 cur_batch---- 99 g_step**** 25523 cost 7.540188
save checkpoint 25600
cur_epoch==== 65 cur_batch---- 99 g_step**** 25689 cost 7.5589333
cur_epoch==== 66 cur_batch---- 99 g_step**** 25855 cost 7.2588253
save checkpoint 26000
seq   0: origin: [21, 18, 25, 18] decoded:[51, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 54, 52, 53, 51, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[37, 37, 42, 38, 47]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 73, 83, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 42, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 85, 73, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[51, 38, 53, 34, 45, 51, 34, 47, 53, 52]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 36, 48]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 51, 48, 55, 38, 51]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[46, 69, 86, 73, 78, 79]
5/10 7:38:25  step===26000, Epoch 68/1000, accuracy = 0.233,avg_train_cost = 7.129, lastbatch_err = 0.406, time = 211.473,lr=0.00770043

cur_epoch==== 67 cur_batch---- 99 g_step**** 26021 cost 6.8951044
cur_epoch==== 68 cur_batch---- 99 g_step**** 26187 cost 6.698186
cur_epoch==== 69 cur_batch---- 99 g_step**** 26353 cost 7.886005
save checkpoint 26400
cur_epoch==== 70 cur_batch---- 99 g_step**** 26519 cost 6.805972
cur_epoch==== 71 cur_batch---- 99 g_step**** 26685 cost 7.393744
save checkpoint 26800
cur_epoch==== 72 cur_batch---- 99 g_step**** 26851 cost 6.9075155
seq   0: origin: [21, 18, 25, 18] decoded:[34, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 54, 36, 53, 34, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 37, 42, 37, 42, 37]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 73, 83, 65, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 65, 73, 83, 73, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 73, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 42, 52, 34, 37]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 38, 53, 34, 45, 51, 34, 47, 53, 42, 51]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 36, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 51, 48, 55, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 48, 42, 45]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[46, 69, 82, 73, 78, 79]
5/10 8:23:7  step===27000, Epoch 74/1000, accuracy = 0.256,avg_train_cost = 6.970, lastbatch_err = 0.395, time = 222.713,lr=0.00762343

cur_epoch==== 73 cur_batch---- 99 g_step**** 27017 cost 7.44207
cur_epoch==== 74 cur_batch---- 99 g_step**** 27183 cost 6.605255
save checkpoint 27200
cur_epoch==== 75 cur_batch---- 99 g_step**** 27349 cost 6.3390293
cur_epoch==== 76 cur_batch---- 99 g_step**** 27515 cost 7.0460243
save checkpoint 27600
cur_epoch==== 77 cur_batch---- 99 g_step**** 27681 cost 7.446662
cur_epoch==== 78 cur_batch---- 99 g_step**** 27847 cost 6.4332194
save checkpoint 28000
seq   0: origin: [21, 18, 25, 18] decoded:[34, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 52, 38, 53, 51, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 43, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 37, 42, 52, 42, 37, 47]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 73, 83, 69, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 54, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 65, 73, 76, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[87, 73, 76, 76]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 52, 38]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 38, 53, 34, 45, 51, 34, 47, 53, 51]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[36, 48, 52, 36, 48]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[53, 48, 51, 48, 55, 38, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 48, 42, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[77, 69, 82, 73, 78, 79]
5/10 9:7:47  step===28000, Epoch 80/1000, accuracy = 0.262,avg_train_cost = 6.761, lastbatch_err = 0.398, time = 232.626,lr=0.00754719

cur_epoch==== 79 cur_batch---- 99 g_step**** 28013 cost 6.3216696
cur_epoch==== 80 cur_batch---- 99 g_step**** 28179 cost 6.54642
cur_epoch==== 81 cur_batch---- 99 g_step**** 28345 cost 6.0356035
save checkpoint 28400
cur_epoch==== 82 cur_batch---- 99 g_step**** 28511 cost 6.60211
cur_epoch==== 83 cur_batch---- 99 g_step**** 28677 cost 5.9257045
save checkpoint 28800
cur_epoch==== 84 cur_batch---- 99 g_step**** 28843 cost 5.5565624
seq   0: origin: [21, 18, 25, 18] decoded:[18, 18, 35, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 54, 40, 53, 34, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 37, 47, 52, 42, 48, 47]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 82, 65, 69, 84]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 85, 73, 83, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 73, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 48, 38, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[82, 69, 84, 72, 76, 82, 65, 78, 82]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 67, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[46, 48, 48, 55, 38, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 79, 73, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[46, 69, 82, 73, 78, 79]
5/10 9:52:28  step===29000, Epoch 86/1000, accuracy = 0.289,avg_train_cost = 6.590, lastbatch_err = 0.378, time = 243.451,lr=0.00747172

cur_epoch==== 85 cur_batch---- 99 g_step**** 29009 cost 7.515988
cur_epoch==== 86 cur_batch---- 99 g_step**** 29175 cost 5.669955
save checkpoint 29200
cur_epoch==== 87 cur_batch---- 99 g_step**** 29341 cost 6.6884365
cur_epoch==== 88 cur_batch---- 99 g_step**** 29507 cost 6.8268924
save checkpoint 29600
cur_epoch==== 89 cur_batch---- 99 g_step**** 29673 cost 6.824674
cur_epoch==== 90 cur_batch---- 99 g_step**** 29839 cost 6.956376
save checkpoint 30000
seq   0: origin: [21, 18, 25, 18] decoded:[34, 18, 35, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 45, 52, 38, 53, 34, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 45, 42, 47, 47, 42, 48, 47]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[80, 82, 73, 79, 69, 69, 77]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 54, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[52, 85, 83, 76, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 42, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[51, 48, 52, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[69, 84, 65, 76, 82, 65, 78, 84, 82]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 67, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[53, 48, 47, 48, 39, 38, 38]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 48, 42, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[46, 69, 82, 73, 82, 79]
5/10 10:37:11  step===30000, Epoch 92/1000, accuracy = 0.272,avg_train_cost = 6.446, lastbatch_err = 0.376, time = 254.189,lr=0.00739701

cur_epoch==== 91 cur_batch---- 99 g_step**** 30005 cost 6.140682
cur_epoch==== 92 cur_batch---- 99 g_step**** 30171 cost 6.7493954
cur_epoch==== 93 cur_batch---- 99 g_step**** 30337 cost 5.8173747
save checkpoint 30400
cur_epoch==== 94 cur_batch---- 99 g_step**** 30503 cost 6.2715797
cur_epoch==== 95 cur_batch---- 99 g_step**** 30669 cost 5.816868
save checkpoint 30800
cur_epoch==== 96 cur_batch---- 99 g_step**** 30835 cost 4.932804
seq   0: origin: [21, 18, 25, 18] decoded:[65, 18, 25, 18]
seq   1: origin: [38, 45, 38, 36, 53, 51, 42, 36] decoded:[38, 52, 36, 53, 51, 42, 36]
seq   2: origin: [38, 34, 40, 45, 38] decoded:[38, 34, 52, 45, 38]
seq   3: origin: [56, 34, 52, 41, 42, 47, 40, 53, 48, 47] decoded:[34, 45, 42, 37, 42, 37, 52]
seq   4: origin: [49, 82, 79, 74, 69, 67, 84] decoded:[37, 82, 73, 71, 69, 15, 77]
seq   5: origin: [36, 48, 48, 44, 42, 38, 52] decoded:[36, 48, 48, 44, 53, 38, 52]
seq   6: origin: [37, 69, 82, 80, 69, 82] decoded:[68, 79, 82, 80, 69, 82]
seq   7: origin: [83, 87, 73, 78, 76, 76, 69] decoded:[83, 85, 73, 83, 76, 76, 69]
seq   8: origin: [56, 42, 45, 45] decoded:[56, 42, 45, 45]
seq   9: origin: [73, 78, 84, 69, 82, 70, 65, 67, 69, 83] decoded:[73, 78, 84, 69, 82, 70, 65, 67, 69, 83]
seq  10: origin: [48, 47, 38, 34, 45] decoded:[53, 51, 48, 42, 52, 48]
seq  11: origin: [67, 79, 77, 80, 65, 78, 89] decoded:[67, 79, 77, 80, 65, 78, 89]
seq  12: origin: [37, 51, 42, 47, 44] decoded:[37, 51, 42, 47, 44]
seq  13: origin: [51, 38, 52, 53, 34, 54, 51, 34, 47, 53] decoded:[49, 51, 38, 53, 34, 45, 51, 34, 47, 42, 51]
seq  14: origin: [36, 48, 52, 36, 48] decoded:[67, 79, 83, 36, 79]
seq  15: origin: [43, 48, 51, 53, 48, 55, 48, 57] decoded:[53, 48, 51, 48, 39, 38, 51]
seq  16: origin: [39, 48, 42, 45] decoded:[70, 48, 42, 76]
seq  17: origin: [46, 69, 88, 73, 67, 79] decoded:[46, 69, 82, 73, 78, 79]
5/10 11:21:53  step===31000, Epoch 98/1000, accuracy = 0.282,avg_train_cost = 6.274, lastbatch_err = 0.367, time = 264.403,lr=0.00732304

cur_epoch==== 97 cur_batch---- 99 g_step**** 31001 cost 6.7909636
cur_epoch==== 98 cur_batch---- 99 g_step**** 31167 cost 6.1487565
save checkpoint 31200
cur_epoch==== 99 cur_batch---- 99 g_step**** 31333 cost 6.2643504
cur_epoch==== 100 cur_batch---- 99 g_step**** 31499 cost 6.5258703
save checkpoint 31600
cur_epoch==== 101 cur_batch---- 99 g_step**** 31665 cost 5.6785917
