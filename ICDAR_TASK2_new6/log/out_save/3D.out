nohup: ignoring input
/home/sjhbxs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
###########################################################
SparseTensor(indices=Tensor("BLSTM/Placeholder_2:0", shape=(?, ?), dtype=int64), values=Tensor("BLSTM/Placeholder_1:0", shape=(?,), dtype=int32), dense_shape=Tensor("BLSTM/Placeholder:0", shape=(?,), dtype=int64))
Tensor("transpose:0", shape=(?, ?, 102), dtype=float32)
Tensor("BLSTM/Placeholder_3:0", shape=(?,), dtype=int32)
loading train data, please wait--------------------- end= 
len is 0 or too long 1101121
len is 0 or too long 1067138
len is 0 or too long 1085492
len is 0 or too long 1080026
len is 0 or too long 1148610
len is 0 or too long 1161134
len is 0 or too long 1091637
len is 0 or too long 1234345
len is 0 or too long 1157057
len is 0 or too long 1078701
len is 0 or too long 1199831
len is 0 or too long 1124130
***************get image:  42606
loading validation data, please wait--------------------- end= 
len is 0 or too long 1091637
***************get image:  301
2018-05-15 13:00:11.071158: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-15 13:00:11.071197: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-15 13:00:11.071205: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-05-15 13:00:11.071211: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-15 13:00:11.071218: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-05-15 13:00:11.168938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-15 13:00:11.169296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.09GiB
2018-05-15 13:00:11.169321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-05-15 13:00:11.169330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-05-15 13:00:11.169355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
restore is true
restore from the checkpoint/home/sjhbxs/checkout/ICDAR_task2/ICDAR_TASK2_new6/checkpoint/ocr-model-38000
=============================begin training=============================
2018-05-15 13:00:17.626002: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4577 get requests, put_count=3082 evicted_count=1000 eviction_rate=0.324465 and unsatisfied allocation rate=0.566965
2018-05-15 13:00:17.626079: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2018-05-15 13:00:28.641782: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 372 get requests, put_count=1385 evicted_count=1000 eviction_rate=0.722022 and unsatisfied allocation rate=0.00268817
2018-05-15 13:00:28.641903: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 160 to 176
2018-05-15 13:00:34.859821: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 649 get requests, put_count=1673 evicted_count=1000 eviction_rate=0.597729 and unsatisfied allocation rate=0.00154083
2018-05-15 13:00:42.511340: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 5279 get requests, put_count=5132 evicted_count=2000 eviction_rate=0.389712 and unsatisfied allocation rate=0.413715
2018-05-15 13:00:42.511395: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 409 to 449
2018-05-15 13:00:50.224832: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 5357 get requests, put_count=5484 evicted_count=2000 eviction_rate=0.364697 and unsatisfied allocation rate=0.36065
2018-05-15 13:00:50.224899: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 655 to 720
2018-05-15 13:00:59.519243: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4936 get requests, put_count=4600 evicted_count=1000 eviction_rate=0.217391 and unsatisfied allocation rate=0.291937
2018-05-15 13:00:59.519300: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 1158 to 1273
cur_epoch==== 0 cur_batch---- 99 g_step**** 38099 cost 5.1165886
cur_epoch==== 1 cur_batch---- 99 g_step**** 38265 cost 5.38234
save checkpoint 38400
cur_epoch==== 2 cur_batch---- 99 g_step**** 38431 cost 5.380449
cur_epoch==== 3 cur_batch---- 99 g_step**** 38597 cost 4.7699986
