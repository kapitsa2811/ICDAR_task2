nohup: ignoring input
/home/sjhbxs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
###########################################################
SparseTensor(indices=Tensor("BLSTM/Placeholder_2:0", shape=(?, ?), dtype=int64), values=Tensor("BLSTM/Placeholder_1:0", shape=(?,), dtype=int32), dense_shape=Tensor("BLSTM/Placeholder:0", shape=(?,), dtype=int64))
Tensor("transpose:0", shape=(?, ?, 102), dtype=float32)
Tensor("BLSTM/Placeholder_3:0", shape=(?,), dtype=int32)
loading train data, please wait--------------------- end= 
0
shear1+rotation1+randomColor1_1014762.jpg
len is 0 or too long 1080026
len is 0 or too long 1148610
10000
shear0+rotation1+heightshift_1017194.jpg
len is 0 or too long 1124130
len is 0 or too long 1101121
len is 0 or too long 1085492
20000
shear0+rotation1+widthshift_1198003.jpg
len is 0 or too long 1124130
len is 0 or too long 1101121
len is 0 or too long 1124130
30000
shear1+rotation1_1211508.jpg
len is 0 or too long 1199831
len is 0 or too long 1124130
len is 0 or too long 1157057
40000
shear1+rotation0+heightshift_1200723.jpg
len is 0 or too long 1124130
len is 0 or too long 1157057
50000
shear0+rotation1+randomColor0_1215142.jpg
len is 0 or too long 1199831
60000
shear0+rotation0+widthshift_1078771.jpg
len is 0 or too long 1148610
len is 0 or too long 1234345
len is 0 or too long 1157057
len is 0 or too long 1091637
len is 0 or too long 1078701
70000
shear0+rotation1+PAC Jittering1_1223154.jpg
len is 0 or too long 1161134
len is 0 or too long 1148610
len is 0 or too long 1124130
len is 0 or too long 1078701
80000
shear0+rotation1+heightshift_1025607.jpg
len is 0 or too long 1161134
len is 0 or too long 1101121
len is 0 or too long 1234345
90000
shear0+rotation0+widthshift_1015246.jpg
100000
shear1+rotation1+PAC Jittering0_1003751.jpg
len is 0 or too long 1124130
len is 0 or too long 1091637
110000
shear1+rotation0_1217461.jpg
len is 0 or too long 1101121
len is 0 or too long 1124130
120000
shear1+rotation0+widthshift_1120387.jpg
len is 0 or too long 1157057
len is 0 or too long 1101121
130000
shear0+rotation0+widthshift_1116091.jpg
140000
shear1+rotation1+randomColor0_1218163.jpg
len is 0 or too long 1101121
len is 0 or too long 1067138
len is 0 or too long 1199831
len is 0 or too long 1199831
len is 0 or too long 1101121
150000
shear1+rotation0+heightshift_1002750.jpg
len is 0 or too long 1078701
len is 0 or too long 1067138
len is 0 or too long 1067138
len is 0 or too long 1199831
len is 0 or too long 1085492
160000
shear0+rotation1+randomColor1_1128317.jpg
len is 0 or too long 1085492
len is 0 or too long 1101121
len is 0 or too long 1124130
len is 0 or too long 1078701
len is 0 or too long 1067138
len is 0 or too long 1101121
170000
shear0+rotation1+randomColor2_1027352.jpg
len is 0 or too long 1199831
len is 0 or too long 1078701
180000
shear1+rotation0+PAC Jittering1_1239520.jpg
len is 0 or too long 1067138
len is 0 or too long 1091637
len is 0 or too long 1161134
len is 0 or too long 1101121
len is 0 or too long 1067138
190000
shear0+rotation0_1231479.jpg
len is 0 or too long 1080026
len is 0 or too long 1078701
len is 0 or too long 1234345
200000
shear0+rotation1+heightshift_1235981.jpg
len is 0 or too long 1161134
len is 0 or too long 1078701
len is 0 or too long 1148610
len is 0 or too long 1078701
210000
shear0+rotation1+heightshift_1232099.jpg
len is 0 or too long 1078701
220000
shear0+rotation1+PAC Jittering0_1207828.jpg
get image:  221938
loading validation data, please wait--------------------- end= 
0
shear0+rotation1+PAC Jittering0_1210490.jpg
get image:  822
2018-05-02 04:21:24.504945: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-02 04:21:24.504995: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-05-02 04:21:24.505014: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-05-02 04:21:24.607908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-05-02 04:21:24.608195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 4.71GiB
2018-05-02 04:21:24.608217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-05-02 04:21:24.608225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-05-02 04:21:24.608237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
restore is true
2018-05-02 04:21:26.436245: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.436828: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.438735: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.439225: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.439515: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.440037: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.440160: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.440308: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.442137: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.442547: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.442783: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.442827: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.443608: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.444494: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.444700: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.445130: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.445314: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.446004: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.446229: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.447541: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.447740: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.447885: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.448022: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.448238: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.448997: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.450131: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.450602: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.450732: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.450867: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.451175: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.451621: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.452658: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.452854: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.453022: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.453189: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.453332: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.455106: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.455299: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.455419: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.455553: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.457279: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.457545: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.457676: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.457938: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.459756: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.460245: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.460456: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.462007: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.462188: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.462386: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.463229: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.463356: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.463496: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.464098: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.464953: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.465720: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.466063: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.466640: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.466913: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.466962: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.467100: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.467272: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.467457: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.467963: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.468563: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.468859: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
2018-05-02 04:21:26.468897: W tensorflow/core/framework/op_kernel.cc:1158] Data loss: file is too short to be an sstable
Traceback (most recent call last):
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1139, in _do_call
    return fn(*args)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1121, in _run_fn
    status, run_metadata)
  File "/home/sjhbxs/anaconda3/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.DataLossError: file is too short to be an sstable
	 [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
	 [[Node: save/RestoreV2_9/_9 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send_device_incarnation=1, tensor_name="edge_142_save/RestoreV2_9", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 101, in <module>
    train(train_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_argu', val_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_argu_small', train_text_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_gt.txt',val_text_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_gt.txt')
  File "train.py", line 41, in train
    saver.restore(sess,ckpt)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1548, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 789, in run
    run_metadata_ptr)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 997, in _run
    feed_dict_string, options, run_metadata)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1132, in _do_run
    target_list, options, run_metadata)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DataLossError: file is too short to be an sstable
	 [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
	 [[Node: save/RestoreV2_9/_9 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send_device_incarnation=1, tensor_name="edge_142_save/RestoreV2_9", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"]()]]

Caused by op 'save/RestoreV2_1', defined at:
  File "train.py", line 101, in <module>
    train(train_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_argu', val_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_argu_small', train_text_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_gt.txt',val_text_dir='/home/sjhbxs/Data/data_coco_task2/ICDAR_TASK2_new4/train_data/train_words_gt.txt')
  File "train.py", line 34, in train
    saver = tf.train.Saver(tf.global_variables(),max_to_keep=3)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1139, in __init__
    self.build()
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1170, in build
    restore_sequentially=self._restore_sequentially)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 691, in build
    restore_sequentially, reshape)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 407, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 247, in restore_op
    [spec.tensor.dtype])[0])
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py", line 640, in restore_v2
    dtypes=dtypes, name=name)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/home/sjhbxs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1269, in __init__
    self._traceback = _extract_stack()

DataLossError (see above for traceback): file is too short to be an sstable
	 [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
	 [[Node: save/RestoreV2_9/_9 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send_device_incarnation=1, tensor_name="edge_142_save/RestoreV2_9", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"]()]]

